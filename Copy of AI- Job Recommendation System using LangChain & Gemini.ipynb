{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["NGzL7i7Xv0jA","6L11-KksVvPM","4MbJ4HvxWDak","dZ1bHhNwWWjO","Rx4BgxzPWkGD","mbPs90AcXp8j","sh9FTWSFYeFC","a2VyvMCKZhCM","bzfXqBCiZt9I"],"mount_file_id":"1TXIMTPxyJopphLiBjvxZAwmAVXsqMUy5","authorship_tag":"ABX9TyNlTrozJb4JkZOI71dVtZoA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["####**1. Installing and importing Libraries**"],"metadata":{"id":"NGzL7i7Xv0jA"}},{"cell_type":"code","source":["!pip install -U langchain-community\n","!pip install langchain streamlit chromadb langchain-google-genai\n","from langchain_community.vectorstores import Chroma"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wq2l8KyIPJHP","executionInfo":{"status":"ok","timestamp":1755673858579,"user_tz":-330,"elapsed":17132,"user":{"displayName":"Syed Shakir Sayeed","userId":"03480128925286987157"}},"outputId":"733b1963-d366-479e-eb27-da26638bfcb6"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.3.27)\n","Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.3.74)\n","Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.3.27)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.43)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.32.3)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.2)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.12.15)\n","Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (9.1.2)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n","Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.10.1)\n","Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.14)\n","Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.1)\n","Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n","Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (0.3.9)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (2.11.7)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (1.33)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (4.14.1)\n","Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (25.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\n","Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community) (3.11.2)\n","Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n","Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\n","Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain-community) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain-community) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain-community) (2025.8.3)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.4)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.10.0)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.16.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain-community) (3.0.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (2.33.2)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\n","Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n","Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.48.1)\n","Requirement already satisfied: chromadb in /usr/local/lib/python3.12/dist-packages (1.0.20)\n","Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.12/dist-packages (2.1.9)\n","Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.74)\n","Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.9)\n","Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.14)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.7)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.3)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n","Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n","Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n","Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.2.1)\n","Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n","Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n","Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n","Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n","Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n","Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n","Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (9.1.2)\n","Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n","Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.14.1)\n","Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n","Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n","Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n","Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.4.2)\n","Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.3.0)\n","Requirement already satisfied: pybase64>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.4.2)\n","Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.35.0)\n","Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.4.0)\n","Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.22.1)\n","Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.36.0)\n","Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.36.0)\n","Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.36.0)\n","Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.21.4)\n","Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.48.9)\n","Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.67.1)\n","Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n","Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.74.0)\n","Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.3.0)\n","Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.16.0)\n","Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (33.1.0)\n","Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.2.0)\n","Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.2)\n","Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n","Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.0)\n","Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.2.0)\n","Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.18 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (0.6.18)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n","Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.1.1)\n","Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n","Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.25.1)\n","Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.38.0)\n","Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (4.10.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (2025.8.3)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n","Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.27.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n","Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n","Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n","Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\n","Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.5.0)\n","Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n","Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n","Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n","Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\n","Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n","Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n","Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.36.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.36.0)\n","Requirement already satisfied: opentelemetry-proto==1.36.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.36.0)\n","Requirement already satisfied: opentelemetry-semantic-conventions==0.57b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.57b0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n","Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n","Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.13.2->chromadb) (0.34.4)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n","Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n","Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n","Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n","Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n","Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n","Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.19.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.1.7)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n","Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n"]}]},{"cell_type":"markdown","source":["####**2. Setting Google Gemini API**"],"metadata":{"id":"6L11-KksVvPM"}},{"cell_type":"code","source":["import os\n","from google.colab import userdata\n","os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')"],"metadata":{"id":"PsF12Ca39XNX","executionInfo":{"status":"ok","timestamp":1755673859287,"user_tz":-330,"elapsed":713,"user":{"displayName":"Syed Shakir Sayeed","userId":"03480128925286987157"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["####**3. Scraping LinkedIn job website using Requests and BeautifulSoup**"],"metadata":{"id":"4MbJ4HvxWDak"}},{"cell_type":"code","source":["import requests\n","response = requests.get(\n","    \"https://api.scrapingdog.com/linkedinjobs\",\n","    params={\"api_key\": \"YOUR_SCRAPINGDOG_KEY\", \"field\": \"Python\", \"geoid\": \"YOUR_LOCATION_ID\", \"page\": 1},\n",")\n","jobs = response.json()\n","print(jobs)  # A list of job posting details"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_dv2J_iJ-GAP","executionInfo":{"status":"ok","timestamp":1755673859425,"user_tz":-330,"elapsed":136,"user":{"displayName":"Syed Shakir Sayeed","userId":"03480128925286987157"}},"outputId":"7556815c-02ef-4c24-cdba-959f7c0c48e3"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["{'message': 'user not found', 'success': False}\n"]}]},{"cell_type":"code","source":["%pip install requests beautifulsoup4"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HS3yftAHaQ7q","executionInfo":{"status":"ok","timestamp":1755673882919,"user_tz":-330,"elapsed":23491,"user":{"displayName":"Syed Shakir Sayeed","userId":"03480128925286987157"}},"outputId":"05001ecf-e085-46a9-8edb-c21907f43c9c"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.3)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.7)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.14.1)\n"]}]},{"cell_type":"code","source":["from bs4 import BeautifulSoup\n","import requests\n","\n","def linkedinjobs(search, location, num_pages):\n","    all_jobs = []  # Use a different list to store the parsed job data\n","    for page in range(num_pages):\n","        url = f\"https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords={search}&location={location}&start={page * 10}\"\n","        html = requests.get(url).text\n","        soup = BeautifulSoup(html, 'html.parser')\n","        jobs_on_page = soup.find_all('li') # This is the BeautifulSoup ResultSet\n","\n","        for job in jobs_on_page:  # Iterate over the BeautifulSoup objects\n","            info = job.select_one('.base-search-card__info')\n","            if not info:\n","                continue\n","\n","            title = info.select_one('.base-search-card__title')\n","            company = info.select_one('.base-search-card__subtitle')\n","            location = info.select_one('.job-search-card__location')\n","\n","            all_jobs.append({\n","                \"title\": title.get_text(strip=True) if title else \"\",\n","                \"company\": company.get_text(strip=True) if company else \"\",\n","                \"location\": location.get_text(strip=True) if location else \"\"\n","            })\n","    return all_jobs # Return the list of dictionaries\n","\n","jobs_list = linkedinjobs(\"data analyst\", \"India\", 5) # Call the function and store the result in a new variable\n","# Inspect the result\n","for jobs in jobs_list[:50]:\n","  print(jobs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pTs5NEJLB5i9","executionInfo":{"status":"ok","timestamp":1755673886409,"user_tz":-330,"elapsed":3485,"user":{"displayName":"Syed Shakir Sayeed","userId":"03480128925286987157"}},"outputId":"91196664-0b73-470f-a216-339cda92c6bb"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["{'title': 'Junior Data Analyst', 'company': 'NxtWave', 'location': 'Hyderabad, Telangana, India'}\n","{'title': 'Data Analyst - Alteryx', 'company': 'LTIMindtree', 'location': 'Mumbai, Maharashtra, India'}\n","{'title': 'Data Analyst', 'company': 'Experian', 'location': 'Mumbai Metropolitan Region'}\n","{'title': 'Data Analyst (1 year contract)', 'company': 'H&M', 'location': 'Bengaluru, Karnataka, India'}\n","{'title': 'Data Analyst, Mumbai', 'company': 'Puma Energy', 'location': 'Mumbai Metropolitan Region'}\n","{'title': 'Data Analyst', 'company': 'Coursera', 'location': 'Gurgaon, Haryana, India'}\n","{'title': 'Data Analyst', 'company': 'O.P. Jindal Global University (JGU)', 'location': 'Sonipat, Haryana, India'}\n","{'title': 'Insights Specialist', 'company': 'Google', 'location': 'Gurugram, Haryana, India'}\n","{'title': 'Analyst/Senior Analyst - Data Analytics (SQL/Python)', 'company': 'American Express', 'location': 'Gurugram, Haryana, India'}\n","{'title': 'Data Analyst', 'company': 'Optum', 'location': 'Gurugram, Haryana, India'}\n","{'title': 'Analyst', 'company': 'EXL', 'location': 'Gurugram, Haryana, India'}\n","{'title': 'Analyst/Senior Analyst - Data Analytics (SQL/Python)', 'company': 'American Express', 'location': 'Gurugram, Haryana, India'}\n","{'title': 'HR Data Analyst', 'company': 'TrueBlue Inc.', 'location': 'Gurugram, Haryana, India'}\n","{'title': 'Data Analyst', 'company': 'Gartner', 'location': 'Gurgaon, Haryana, India'}\n","{'title': 'Insights and Analytics Specialist [T500-19284]', 'company': 'Careem', 'location': 'Delhi, India'}\n","{'title': 'Data Associate - Gurgaon', 'company': 'Circles', 'location': 'Gurgaon, Haryana, India'}\n","{'title': 'Data Analyst', 'company': 'Maxima Apparel', 'location': 'Gurgaon Rural, Haryana, India'}\n","{'title': 'Data Analyst', 'company': 'Cushman & Wakefield', 'location': 'Gurgaon, Haryana, India'}\n","{'title': 'Lead Data Analyst', 'company': 'Airtel Digital', 'location': 'Gurugram, Haryana, India'}\n","{'title': 'Data Analyst', 'company': 'SAKU', 'location': 'Gurugram, Haryana, India'}\n","{'title': 'Data Analyst, Client Data, Tech & Ops', 'company': 'BlackRock', 'location': 'Gurgaon, Haryana, India'}\n","{'title': 'Data Analyst', 'company': 'Appinventiv', 'location': 'Noida, Uttar Pradesh, India'}\n","{'title': 'Data Analyst - EV & CW', 'company': 'Circle K', 'location': 'Gurugram, Haryana, India'}\n","{'title': 'Data Analyst', 'company': 'TELUS Digital', 'location': 'Noida, Uttar Pradesh, India'}\n","{'title': 'Data Analyst - Advance SQL and Excel - BPO Industry', 'company': 'TELUS Digital', 'location': 'Gurugram, Haryana, India'}\n","{'title': 'Senior Analyst-Data Analytics', 'company': 'American Express', 'location': 'Gurugram, Haryana, India'}\n","{'title': 'Lead Data Analyst', 'company': 'Zupee', 'location': 'Gurugram, Haryana, India'}\n","{'title': 'Knowledge Analyst', 'company': 'McKinsey & Company', 'location': 'Gurugram, Haryana, India'}\n","{'title': 'Fraud Data Analyst', 'company': 'Airtel Payments Bank', 'location': 'Gurugram, Haryana, India'}\n","{'title': 'Senior Data Analyst', 'company': 'EXL', 'location': 'Gurugram, Haryana, India'}\n","{'title': 'Data Analyst- GCOC', 'company': 'Criteo', 'location': 'Gurgaon, Haryana, India'}\n","{'title': 'Data Analyst', 'company': 'Nat Habit', 'location': 'Gurugram, Haryana, India'}\n","{'title': 'Sr Analyst-Data Analytics', 'company': 'American Express', 'location': 'Gurgaon, Haryana, India'}\n","{'title': 'Associate Analyst', 'company': 'Trinity Life Sciences', 'location': 'Gurgaon, Haryana, India'}\n","{'title': 'Executive - Data Analytics', 'company': 'KPMG India', 'location': 'Gurgaon, Haryana, India'}\n","{'title': 'Data Analyst -Survey Administration', 'company': 'Mercer', 'location': 'Gurugram, Haryana, India'}\n","{'title': 'Result Processing Trainee', 'company': 'PW (PhysicsWallah)', 'location': 'Noida, Uttar Pradesh, India'}\n","{'title': 'Data Analyst', 'company': 'HT Digital Streams', 'location': 'Delhi, India'}\n","{'title': 'Data Analyst| Research | Gurugram', 'company': 'Cushman & Wakefield', 'location': 'Gurgaon, Haryana, India'}\n","{'title': 'Data Analyst -Survey Administration', 'company': 'Mercer', 'location': 'Gurugram, Haryana, India'}\n","{'title': 'Business Data Analyst', 'company': 'Starcom Consultant', 'location': 'Delhi, India'}\n","{'title': 'Lead Data Analyst', 'company': 'Zupee', 'location': 'Gurugram, Haryana, India'}\n","{'title': 'Analytics & Insights Specialist', 'company': 'Gartner', 'location': 'Gurgaon, Haryana, India'}\n","{'title': 'Data Science Analyst - Periscope', 'company': 'McKinsey & Company', 'location': 'Gurugram, Haryana, India'}\n","{'title': 'Analyst-Control Management (Data Analytics -Python and SQL)', 'company': 'American Express', 'location': 'Gurgaon, Haryana, India'}\n","{'title': 'Data Analyst', 'company': 'NCR Atleos', 'location': 'Gurgaon, Haryana, India'}\n","{'title': 'Associate - Data Analyst', 'company': 'Acuity Knowledge Partners', 'location': 'Gurugram, Haryana, India'}\n","{'title': 'Data Analyst- GCOC', 'company': 'Criteo', 'location': 'Gurgaon, Haryana, India'}\n"]}]},{"cell_type":"markdown","source":["####**4. Storing the jobs data in JSON format**"],"metadata":{"id":"dZ1bHhNwWWjO"}},{"cell_type":"code","source":["import json\n","from google.colab import files\n","import os\n","\n","# Assuming jobs_list is available from previous cell execution\n","\n","# Define the folder name and filename\n","folder_name = '/content/drive/MyDrive/DS_Notes/ALMAX_Lite/GenerativeAI/AI_Job_Recommendation/Data'\n","filename = 'linkedin_jobs.json'\n","filepath = os.path.join(folder_name, filename)\n","\n","# Create the folder if it doesn't exist\n","os.makedirs(folder_name, exist_ok=True)\n","\n","# Save the jobs_list to a JSON file inside the folder\n","with open(filepath, 'w') as f:\n","    json.dump(jobs_list, f, indent=4)\n","\n","print(f\"'{filename}' has been saved in the '{folder_name}' folder.\")\n","\n","# Make the file downloadable\n","files.download(filepath)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"lLK2EF7YTzOO","executionInfo":{"status":"ok","timestamp":1755673886508,"user_tz":-330,"elapsed":90,"user":{"displayName":"Syed Shakir Sayeed","userId":"03480128925286987157"}},"outputId":"7c2f89fa-5ef6-4bc8-d764-51408b7510be"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["'linkedin_jobs.json' has been saved in the '/content/drive/MyDrive/DS_Notes/ALMAX_Lite/GenerativeAI/AI_Job_Recommendation/Data' folder.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_8b6ced8c-e54e-4897-8d29-5473c176375f\", \"linkedin_jobs.json\", 6637)"]},"metadata":{}}]},{"cell_type":"code","source":["!pip install -qU langchain-chroma chromadb"],"metadata":{"id":"l9Uj0B8rQO03","executionInfo":{"status":"ok","timestamp":1755673908207,"user_tz":-330,"elapsed":21704,"user":{"displayName":"Syed Shakir Sayeed","userId":"03480128925286987157"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["####**5. Storing the job data in Vector Embeddings in Chroma Database**"],"metadata":{"id":"Rx4BgxzPWkGD"}},{"cell_type":"code","source":["from langchain_chroma import Chroma\n","from langchain.schema import Document\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain_google_genai import GoogleGenerativeAIEmbeddings\n","from google.colab import userdata\n","\n","# Prepare documents\n","# Assuming 'jobs_list' is already populated from the previous cell's execution\n","documents = [Document(page_content=f\"{job['title']} at {job['company']} in {job['location']}\", metadata=job) for job in jobs_list]\n","\n","# Split into chunks\n","splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n","chunk_docs = []\n","for doc in documents:\n","    for chunk in splitter.split_text(doc.page_content):\n","        chunk_docs.append(Document(page_content=chunk, metadata=doc.metadata))\n","\n","# Embeddings\n","embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=userdata.get('GOOGLE_API_KEY'))\n","\n","# Chroma vector store\n","vectordb = Chroma.from_documents(documents=chunk_docs, embedding=embeddings)\n","\n","# Create a retriever\n","retriever = vectordb.as_retriever()\n","\n","print(\"Vector store and retriever initialized successfully!\")"],"metadata":{"id":"knhgsL-3aUCV","executionInfo":{"status":"ok","timestamp":1755673910054,"user_tz":-330,"elapsed":1825,"user":{"displayName":"Syed Shakir Sayeed","userId":"03480128925286987157"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e2b49cb6-8c99-4395-917f-9d43d4a9d31b"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Vector store and retriever initialized successfully!\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"62ff1d21","executionInfo":{"status":"ok","timestamp":1755673911998,"user_tz":-330,"elapsed":1912,"user":{"displayName":"Syed Shakir Sayeed","userId":"03480128925286987157"}},"outputId":"f083a0c1-f964-42c8-a900-f2d930eabe03"},"source":["from langchain_chroma import Chroma\n","from langchain.schema import Document\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain_google_genai import GoogleGenerativeAIEmbeddings\n","from google.colab import userdata\n","\n","def initialize_vector_store(jobs_list, chunk_size=500, chunk_overlap=50):\n","    \"\"\"Initializes a Chroma vector store and retriever with job data.\n","\n","    Args:\n","        jobs_list: A list of dictionaries containing job information.\n","        chunk_size: The size of the text chunks.\n","        chunk_overlap: The overlap between text chunks.\n","\n","    Returns:\n","        A Chroma retriever initialized with the job data.\n","    \"\"\"\n","    # Prepare documents\n","    documents = [Document(page_content=f\"{job['title']} at {job['company']} in {job['location']}\", metadata=job) for job in jobs_list]\n","\n","    # Split into chunks\n","    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n","    chunk_docs = []\n","    for doc in documents:\n","        for chunk in splitter.split_text(doc.page_content):\n","            chunk_docs.append(Document(page_content=chunk, metadata=doc.metadata))\n","\n","    # Embeddings\n","    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=userdata.get('GOOGLE_API_KEY'))\n","\n","    # Chroma vector store\n","    vectordb = Chroma.from_documents(documents=chunk_docs, embedding=embeddings)\n","\n","    # Create a retriever\n","    retriever = vectordb.as_retriever()\n","\n","    print(\"Vector store and retriever initialized successfully!\")\n","    return retriever\n","\n","\n","# Example usage (assuming jobs_list is available from previous cell execution)\n","retriever = initialize_vector_store(jobs_list)"],"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Vector store and retriever initialized successfully!\n"]}]},{"cell_type":"markdown","source":["####**6. Turning Chroma database into a Retriever, which searches for most relevant jobs based on the given prompt using Prompt Template**"],"metadata":{"id":"mbPs90AcXp8j"}},{"cell_type":"code","source":["from langchain.chains import RetrievalQA\n","from langchain_google_genai import ChatGoogleGenerativeAI\n","from langchain_core.prompts import PromptTemplate\n","from google.colab import userdata\n","\n","# Assuming 'jobs_list' is available from previous cell execution\n","# Initialize the retriever using the function\n","retriever = initialize_vector_store(jobs_list)\n","\n","# Define the prompt template\n","template = \"\"\"Use the following pieces of context to answer the question at the end.\n","If you don't know the answer, just say that you don't know, don't try to make up an answer.\n","Use three sentences maximum and keep the answer as concise as possible.\n","Always say \"Thanks for asking!\" at the end of the answer.\n","\n","{context}\n","\n","Question: {question}\n","\n","Helpful Answer:\"\"\"\n","QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n","\n","# Initialize the Google Generative AI model\n","llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-latest\", google_api_key=userdata.get('GOOGLE_API_KEY'))\n","\n","# Create the Retrieval QA chain\n","qa_chain = RetrievalQA.from_chain_type(\n","    llm,\n","    retriever=retriever,\n","    return_source_documents=True,\n","    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",")\n","\n","# Run the chain with a sample query\n","query = \"What are some data analyst jobs in Bangalore?\"\n","result = qa_chain.invoke({\"query\": query})\n","\n","print(result[\"result\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9vUwc8dfBYqM","executionInfo":{"status":"ok","timestamp":1755673915074,"user_tz":-330,"elapsed":3048,"user":{"displayName":"Syed Shakir Sayeed","userId":"03480128925286987157"}},"outputId":"177ae56b-3ce0-44bb-b5e3-b47e231e154e"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Vector store and retriever initialized successfully!\n","I don't know.  The provided text only mentions Data Analyst positions in Noida. Thanks for asking!\n"]}]},{"cell_type":"code","source":["from langchain.chains import RetrievalQA\n","from langchain_google_genai import ChatGoogleGenerativeAI\n","from langchain_core.prompts import PromptTemplate\n","from google.colab import userdata\n","from langchain_core.runnables import RunnablePassthrough\n","from langchain_core.output_parsers import StrOutputParser\n","from langchain_core.runnables import RunnableParallel\n","\n","def get_job_recommendations_with_sources(retriever, llm, prompt, user_profile):\n","    \"\"\"\n","    Sets up and runs a RAG chain to get job recommendations and source documents.\n","\n","    Args:\n","        retriever: The initialized vector store retriever.\n","        llm: The initialized language model.\n","        prompt: The prompt template.\n","        user_profile: The user's skills and preferences string.\n","\n","    Returns:\n","        A dictionary containing the recommended jobs (answer) and source documents.\n","    \"\"\"\n","    # Build the RAG chain using LCEL to return both answer and sources\n","    rag_chain_with_sources = RunnableParallel(\n","        answer= (\n","            {\"context\": retriever, \"query\": RunnablePassthrough()}\n","            | prompt\n","            | llm\n","            | StrOutputParser()\n","        ),\n","        sources= RunnablePassthrough() | retriever # Directly pass the original query to the retriever\n","    )\n","\n","    response_with_sources = rag_chain_with_sources.invoke(user_profile)\n","    return response_with_sources\n","\n","# Assuming retriever, llm, and prompt are initialized from previous cells\n","\n","# Define the prompt template\n","prompt_template = \"\"\"\n","You are an AI job recommendation assistant.\n","Given the user's skills and preferences, recommend up to four different and most relevant job openings from the retrieved postings.\n","Ensure the recommendations are distinct job titles.\n","\n","User profile:\n","{query}\n","\n","Relevant jobs:\n","{context}\n","\n","Provide recommendations in bullet points with job title, company, and location. If you cannot find four distinct jobs, provide as many distinct ones as possible.\n","\"\"\"\n","\n","prompt = PromptTemplate.from_template(prompt_template)\n","\n","# Example usage\n","user_profile = \"Skills: Python, Data Analysis, Machine Learning..\"\n","recommendations = get_job_recommendations_with_sources(retriever, llm, prompt, user_profile)\n","print(\"Recommended Jobs:\\n\", recommendations[\"answer\"])\n","for i, doc in enumerate(recommendations[\"sources\"], start=1):\n","    print(f\"\\nSource {i}:\")\n","    print(doc.page_content)"],"metadata":{"id":"T-xkRIW7P-vr","colab":{"base_uri":"https://localhost:8080/"},"outputId":"48bc540d-b2bd-48e1-9ee9-10a13cf5fef6","executionInfo":{"status":"ok","timestamp":1755673916121,"user_tz":-330,"elapsed":1031,"user":{"displayName":"Syed Shakir Sayeed","userId":"03480128925286987157"}}},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Recommended Jobs:\n"," * **Data Analyst** at Coursera, Gurgaon, Haryana, India\n","\n","\n","There is only one distinct job title in the provided data.  The other postings are all for the same role.  To provide more relevant recommendations,  more diverse job postings are needed.\n","\n","Source 1:\n","Data Analyst at Coursera in Gurgaon, Haryana, India\n","\n","Source 2:\n","Data Analyst at Coursera in Gurgaon, Haryana, India\n","\n","Source 3:\n","Data Analyst at Coursera in Gurgaon, Haryana, India\n","\n","Source 4:\n","Data Analyst at Coursera in Gurgaon, Haryana, India\n"]}]},{"cell_type":"markdown","source":["####**7. Creating a streamlit App to Run the Application in the browser**"],"metadata":{"id":"sh9FTWSFYeFC"}},{"cell_type":"code","source":["import os\n","import streamlit as st\n","from langchain_chroma import Chroma\n","from langchain.prompts import PromptTemplate\n","from langchain.chains import RetrievalQA\n","from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n","from google.colab import userdata\n","import tempfile\n","from langchain.schema import Document # Import Document\n","from langchain.text_splitter import RecursiveCharacterTextSplitter # Import RecursiveCharacterTextSplitter\n","\n","# --- Helper function to initialize vector store (adapted for Streamlit in Colab) ---\n","@st.cache_resource\n","def initialize_vector_store_for_streamlit(job_data):\n","    \"\"\"Initializes a Chroma vector store and retriever with job data.\"\"\"\n","    if not job_data:\n","        st.error(\"Job data is empty. Please ensure the data loading cell was run successfully.\")\n","        return None\n","\n","    documents = [Document(page_content=f\"{job['title']} at {job['company']} in {job['location']}\", metadata=job) for job in job_data]\n","\n","    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n","    chunk_docs = []\n","    for doc in documents:\n","        for chunk in splitter.split_text(doc.page_content):\n","            chunk_docs.append(Document(page_content=chunk, metadata=doc.metadata))\n","\n","    google_api_key = userdata.get('GOOGLE_API_KEY')\n","    if not google_api_key:\n","        st.error(\"Google API Key not found in Colab secrets. Please add it as 'GOOGLE_API_KEY'.\")\n","        return None\n","\n","    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=google_api_key)\n","\n","    vectordb = Chroma.from_documents(documents=chunk_docs, embedding=embeddings)\n","\n","    retriever = vectordb.as_retriever()\n","\n","    st.success(\"Vector store and retriever initialized successfully!\")\n","    return retriever\n","\n","# Store the streamlit app code in a variable\n","streamlit_code = \"\"\"\n","import os\n","import streamlit as st\n","from langchain_chroma import Chroma\n","from langchain.prompts import PromptTemplate\n","from langchain.chains import RetrievalQA\n","from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n","from google.colab import userdata\n","import tempfile\n","from langchain.schema import Document\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","\n","# --- Helper function to initialize vector store (adapted for Streamlit in Colab) ---\n","@st.cache_resource\n","def initialize_vector_store_for_streamlit(job_data):\n","    \\\"\\\"\\\"Initializes a Chroma vector store and retriever with job data.\\\"\\\"\\\"\n","    if not job_data:\n","        st.error(\"Job data is empty. Please ensure the data loading cell was run successfully.\")\n","        return None\n","\n","    documents = [Document(page_content=f\"{job['title']} at {job['company']} in {job['location']}\", metadata=job) for job in job_data]\n","\n","    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n","    chunk_docs = []\n","    for doc in documents:\n","        for chunk in splitter.split_text(doc.page_content):\n","            chunk_docs.append(Document(page_content=chunk, metadata=doc.metadata))\n","\n","    google_api_key = userdata.get('GOOGLE_API_KEY')\n","    if not google_api_key:\n","        st.error(\"Google API Key not found in Colab secrets. Please add it as 'GOOGLE_API_KEY'.\")\n","        return None\n","\n","    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=google_api_key)\n","\n","    vectordb = Chroma.from_documents(documents=chunk_docs, embedding=embeddings)\n","\n","    retriever = vectordb.as_retriever()\n","\n","    st.success(\"Vector store and retriever initialized successfully!\")\n","    return retriever\n","\n","# --- Load and Initialize ---\n","# Assuming jobs_list is available from previous cell execution (Note: In a real script, you'd load this from a file)\n","# For this example in Colab, we'll assume jobs_list is globally available from previous cells\n","# In a standalone app.py, you would load your data here.\n","try:\n","    # Access jobs_list from the global scope if running in Colab notebook\n","    # In a standalone script, you would load your data from a file here.\n","    # For demonstration in Colab, we assume jobs_list is available.\n","    # Replace with your data loading logic if running as a standalone script.\n","    global jobs_list\n","    if 'jobs_list' not in globals():\n","        st.error(\"Job data (jobs_list) is not available. Please ensure the data loading cell was run successfully in the notebook before saving and running this app.\")\n","        jobs_list = [] # Initialize as empty to prevent further errors\n","\n","    retriever = initialize_vector_store_for_streamlit(jobs_list)\n","except NameError:\n","    st.error(\"Job data (jobs_list) is not available. Please run the data loading and vector store initialization cells first in the notebook.\")\n","    retriever = None\n","\n","\n","if retriever:\n","    google_api_key = userdata.get('GOOGLE_API_KEY') # Access secrets in Colab\n","    if google_api_key:\n","        llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-latest\", temperature=0, google_api_key=google_api_key)\n","    else:\n","        st.error(\"Google API Key not found for LLM. Please add it as 'GOOGLE_API_KEY' in Colab secrets.\")\n","        llm = None\n","\n","    if llm:\n","        prompt_template = \\\"\\\"\\\"\n","        You are an AI job recommendation assistant.\n","        Given the user's skills and preferences, recommend the most relevant job openings from the retrieved postings.\n","\n","        User profile:\n","        {query}\n","\n","        Relevant jobs:\n","        {context}\n","\n","        Provide recommendations in bullet points with job title, company, and location.\n","        \\\"\\\"\\\"\n","        prompt = PromptTemplate(\n","            template=prompt_template,\n","            input_variables=[\"query\", \"context\"]\n","        )\n","\n","        qa_chain = RetrievalQA.from_chain_type(\n","            llm=llm,\n","            retriever=retriever,\n","            chain_type=\"stuff\",\n","            chain_type_kwargs={\"prompt\": prompt},\n","            return_source_documents=True,\n","            input_key=\"query\"\n","        )\n","\n","        # Streamlit UI\n","        st.title(\"💼 AI Job Recommendation System\")\n","        st.write(\"Discover jobs that fit your skills & preferences.\")\n","\n","        user_input = st.text_area(\"Enter your skills, experience, and job preferences:\")\n","        # Upload functionality is not fully implemented for resume parsing in this example\n","        uploaded_file = st.file_uploader(\"Upload your resume (Optional):\", type=[\"pdf\", \"docx\", \"txt\"])\n","\n","        resume_content = \"\"\n","        if uploaded_file is not None:\n","            # In a real application, you would add resume parsing logic here\n","            st.info(f\"Resume '{uploaded_file.name}' uploaded. (Resume parsing functionality not implemented in this example)\")\n","            # Example of how you might read a text file:\n","            # if uploaded_file.type == \"text/plain\":\n","            #     resume_content = uploaded_file.getvalue().decode(\"utf-8\")\n","\n","\n","        if st.button(\"Get Recommendations\"):\n","            if user_input.strip() or uploaded_file is not None:\n","                query = user_input.strip()\n","                # If only a resume is uploaded, you might process it and use its content as the query\n","                # For now, we'll just use the user_input text.\n","                # If you implement resume parsing, you would combine or replace query with resume_content\n","                if uploaded_file is not None and not query:\n","                     # This part would be more sophisticated with actual resume parsing\n","                     st.warning(\"Resume uploaded but no text input. Resume parsing not implemented.\")\n","                     query = \"Recommend jobs based on general data analysis skills.\" # Fallback or process resume content\n","\n","                if not query:\n","                    st.warning(\"Please enter your profile information or ensure resume processing is added.\")\n","                else:\n","                    with st.spinner(\"Finding best matches...\"):\n","                        response = qa_chain.invoke({\"query\": query})\n","                    st.subheader(\"Recommended Jobs\")\n","                    st.write(response[\"result\"])\n","\n","                    with st.expander(\"See Source Job Descriptions\"):\n","                        if response[\"source_documents\"]:\n","                            for i, doc in enumerate(response[\"source_documents\"], start=1):\n","                                st.markdown(f\"**Source {i}:**\")\n","                                st.write(doc.page_content)\n","                        else:\n","                            st.info(\"No source documents found for this query.\")\n","            else:\n","                st.warning(\"Please enter your profile information or upload a resume.\")\n","\n","    else:\n","        st.error(\"LLM could not be initialized. Please check your Google API Key.\")\n","else:\n","    st.error(\"Retriever could not be initialized. Please check the job data and API key.\")\n","\"\"\"\n","\n","# The rest of the code in this cell (if any) would be executed after streamlit_code is defined.\n","# However, since the Streamlit app should be saved to a file and run separately,\n","# there's no need to execute the app code directly here.\n","# The primary purpose of THIS cell is now just to define the streamlit_code string.\n","\n","# Any subsequent cells that use streamlit_code will now have access to it."],"metadata":{"id":"JjA0muk0z4fD","executionInfo":{"status":"ok","timestamp":1755675797421,"user_tz":-330,"elapsed":36,"user":{"displayName":"Syed Shakir Sayeed","userId":"03480128925286987157"}}},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":["####**8. Saving the Streamlit app.py file in the folder**"],"metadata":{"id":"RefMHEWsZD09"}},{"cell_type":"code","source":["import os\n","from google.colab import files\n","\n","# Assuming streamlit_code is available from cell VLF3CKHwssbp\n","\n","# Define the folder name and filename\n","folder_name = '/content/drive/MyDrive/DS_Notes/ALMAX_Lite/GenerativeAI/AI_Job_Recommendation'\n","filename = 'app.py'\n","filepath = os.path.join(folder_name, filename)\n","\n","# Create the folder if it doesn't exist\n","os.makedirs(folder_name, exist_ok=True)\n","\n","# Save the streamlit_code to a Python file inside the folder\n","try:\n","    with open(filepath, 'w') as f:\n","        # Access the streamlit_code variable from the notebook's global scope\n","        f.write(streamlit_code)\n","    print(f\"'{filename}' has been saved in the '{folder_name}' folder.\")\n","\n","    # Make the file downloadable\n","    files.download(filepath)\n","\n","except NameError:\n","    print(\"Error: 'streamlit_code' variable not found. Please ensure the cell defining the Streamlit code (cell VLF3CKHwssbp) has been executed.\")\n","except Exception as e:\n","    print(f\"An error occurred: {e}\")"],"metadata":{"id":"IO0TxqqnSHzL","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1755675850583,"user_tz":-330,"elapsed":36,"user":{"displayName":"Syed Shakir Sayeed","userId":"03480128925286987157"}},"outputId":"d8117dc0-4138-4735-f261-2623592b1e78"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["'app.py' has been saved in the '/content/drive/MyDrive/DS_Notes/ALMAX_Lite/GenerativeAI/AI_Job_Recommendation' folder.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_c6116279-7fda-4fd9-9fc9-6cc341dcbf17\", \"app.py\", 6836)"]},"metadata":{}}]},{"cell_type":"markdown","source":["####**9. Creating and Saving the Requirements.txt file in the folder**"],"metadata":{"id":"a2VyvMCKZhCM"}},{"cell_type":"code","source":["import os\n","\n","# Define the folder name and filename\n","folder_name = '/content/drive/MyDrive/DS_Notes/ALMAX_Lite/GenerativeAI/AI_Job_Recommendation'\n","filename = 'requirements.txt'\n","filepath = os.path.join(folder_name, filename)\n","\n","# Create the folder if it doesn't exist\n","os.makedirs(folder_name, exist_ok=True)\n","\n","# Save the requirements to a file inside the folder\n","with open(filepath, \"w\") as f:\n","    f.write(\"streamlit\\nlangchain\\nlangchain-google-genai\\nchromadb\\npython-dotenv\\n\")\n","\n","print(f\"'{filename}' has been saved in the '{folder_name}' folder.\")"],"metadata":{"id":"9h7hm70e0Ldd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755673919053,"user_tz":-330,"elapsed":59,"user":{"displayName":"Syed Shakir Sayeed","userId":"03480128925286987157"}},"outputId":"8ede5478-5de8-478a-ba9c-c8b5995feb1b"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["'requirements.txt' has been saved in the '/content/drive/MyDrive/DS_Notes/ALMAX_Lite/GenerativeAI/AI_Job_Recommendation' folder.\n"]}]},{"cell_type":"markdown","source":["####**10. Downloading  the entire Project in a Zip file to execute  the Application**"],"metadata":{"id":"bzfXqBCiZt9I"}},{"cell_type":"code","source":["import shutil\n","import os\n","from google.colab import files\n","\n","# Define the folder to zip\n","folder_name = '/content/drive/MyDrive/DS_Notes/ALMAX_Lite/GenerativeAI/AI_Job_Recommendation'\n","zip_filename = 'AI_Job_Recommendation.zip'\n","\n","# Create a zip archive of the folder\n","try:\n","    shutil.make_archive(zip_filename.replace('.zip', ''), 'zip', folder_name)\n","    print(f\"Folder '{folder_name}' zipped successfully as '{zip_filename}'.\")\n","\n","    # Download the zip file\n","    files.download(zip_filename)\n","\n","except Exception as e:\n","    print(f\"An error occurred while zipping or downloading the folder: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"kovlGkUTPhak","executionInfo":{"status":"ok","timestamp":1755673919093,"user_tz":-330,"elapsed":67,"user":{"displayName":"Syed Shakir Sayeed","userId":"03480128925286987157"}},"outputId":"62ffeed0-6bf7-44bb-8aa2-a4672d7dfc56"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Folder '/content/drive/MyDrive/DS_Notes/ALMAX_Lite/GenerativeAI/AI_Job_Recommendation' zipped successfully as 'AI_Job_Recommendation.zip'.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_c971dfb0-fd64-470d-abb6-daeda3d31fb5\", \"AI_Job_Recommendation.zip\", 1478)"]},"metadata":{}}]}]}